{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c611d5",
   "metadata": {},
   "source": [
    "# Deep-Learning with Keras\n",
    "\n",
    "#### Ugur URESIN, AI Engineer | Data Scientist\n",
    "#### Mail: uresin.ugur@gmail.com\n",
    "\n",
    "## Chapter 01. Mathematical Foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63bdea8",
   "metadata": {},
   "source": [
    "#### Data representations for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34489f13",
   "metadata": {},
   "source": [
    "* Data is stored in multidimensional **Numpy arrays**, also called **tensors**.\n",
    "* In general, all current machine-learning systems use tensors as their basic data structure.\n",
    "* Tensors are fundamental to the field—so fundamental that Google’s **TensorFlow** was named after them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5daf639",
   "metadata": {},
   "source": [
    "#### Types of Tensors\n",
    "\n",
    "* **SCALARS (0D Tensors):** Contains only one number is called a scalar.\n",
    "* **VECTORS (1D Tensors):** An array of numbers is called a vector, or 1D tensor. A 1D tensor is said to have exactly one axis.\n",
    "* **MATRICES (2D Tensors):** An array of vectors is a matrix, or 2D tensor. A matrix has two axes (often referred to rows and columns).\n",
    "* **N-DIMENSINONAL TENSORS:** If you pack such matrices in a new array, you obtain a 3D tensor, which you can visually interpret as a cube of numbers. By packing 3D tensors in an array, you can create a 4D tensor, and so on. In deep learning, you’ll generally manipulate tensors that are 0D to 4D, although you may go up to 5D if you process video data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b95b4fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the 0D Tensor: 0\n",
      "Dimension of the 1D Tensor: 1\n",
      "Dimension of the 2D Tensor: 2\n",
      "Dimension of the 3D Tensor: 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 0D TENSOR (Scalar)\n",
    "tensor0d = np.array(3.14)\n",
    "print(\"Dimension of the 0D Tensor:\", tensor0d.ndim)\n",
    "\n",
    "# 1D TENSOR (Vector)\n",
    "tensor1d = np.array([10, 20, 30, 40])\n",
    "print(\"Dimension of the 1D Tensor:\", tensor1d.ndim)\n",
    "\n",
    "# 2D TENSOR (Matrix)\n",
    "tensor2d = np.array([[11, 12, 13, 14],\n",
    "                     [21, 22, 23, 24],\n",
    "                     [31, 32, 33, 34]])\n",
    "print(\"Dimension of the 2D Tensor:\", tensor2d.ndim)\n",
    "\n",
    "# 3D TENSOR\n",
    "tensor3d = np.array([[[11, 12],\n",
    "                      [21, 22]],\n",
    "                     \n",
    "                     [[41, 42],\n",
    "                      [51, 52]]])\n",
    "                     \n",
    "print(\"Dimension of the 3D Tensor:\", tensor3d.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa76336",
   "metadata": {},
   "source": [
    "#### Example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c2df2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data dimensions: 3\n",
      "Image data shape: (60000, 28, 28)\n",
      "Image data type: uint8\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(\"Image data dimensions:\", train_images.ndim)\n",
    "print(\"Image data shape:\", train_images.shape)\n",
    "print(\"Image data type:\", train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeff55f",
   "metadata": {},
   "source": [
    "* The dataset is a 3D tensor of 8-bit integers.\n",
    "* More precisely, it’s an array of 60,000 matrices of 28 × 8 integers.\n",
    "* Each such matrix is a grayscale image, with coefficients between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f516f91",
   "metadata": {},
   "source": [
    "#### Tensor Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3dd3b",
   "metadata": {},
   "source": [
    "* **Number of axes (rank):** For instance, a 3D tensor has three axes, and a matrix has two axes. This is also called the tensor’s ndim in Python libraries such as Numpy.\n",
    "\n",
    "* **Shape:** This is a tuple of integers that describes how many dimensions the tensor has along each axis. For instance, the previous matrix example has shape (3, 5), and the 3D tensor example has shape (3, 3, 5). A vector has a shape with a single element, such as (5,), whereas a scalar has an empty shape, ().\n",
    "\n",
    "* **Data type (usually called dtype in Python libraries):** This is the type of the data contained in the tensor; for instance, a tensor’s type could be float32, uint8, float64, and so on. On rare occasions, you may see a char tensor. Note that string tensors don’t exist in Numpy (or in most other libraries), because tensors live in preallocated, contiguous memory segments: and strings, being variable length, would preclude the use of this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84517fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a734b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image dimensions: (60000, 28, 28)\n",
      "Number of training labels: 60000\n",
      "Test image dimensions: (10000, 28, 28)\n",
      "Number of test labels: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training image dimensions:\", train_images.shape)\n",
    "print(\"Number of training labels:\", len(train_labels))\n",
    "print(\"Test image dimensions:\", test_images.shape)\n",
    "print(\"Number of test labels:\", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b134b743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's look at a one image\n",
    "IMG_INDEX = 1  # change to look at other images\n",
    "\n",
    "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
    "plt.xlabel(train_labels[IMG_INDEX])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be951400",
   "metadata": {},
   "source": [
    "#### Manipulating the Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e055e5",
   "metadata": {},
   "source": [
    "The following example selects digits #10 to #100 (#100 isn’t included) and puts\n",
    "them in an array of shape (90, 28, 28):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9acae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ba58d",
   "metadata": {},
   "source": [
    "It’s equivalent to this more detailed notation, which specifies a start index and stop index for the slice along each tensor axis.  \n",
    "Note that : is equivalent to selecting the entire axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc0a900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :] #Equivalent to the previous example\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c461f366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28] #Equivalent to the previous example\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10012a4",
   "metadata": {},
   "source": [
    "In general, you may select between any two indices along each tensor axis.  \n",
    "For instance, in order to select 14 × 14 pixels in the bottom-right corner of all images, you do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79a41704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 14:, 14:]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62787f0f",
   "metadata": {},
   "source": [
    "It’s also possible to use negative indices.  \n",
    "Much like negative indices in Python lists, they indicate a position relative to the end of the current axis.  \n",
    "In order to crop the images to patches of 14 × 14 pixels centered in the middle, you do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f912f796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d34789d",
   "metadata": {},
   "source": [
    "#### Real-world examples of data tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd7fa5",
   "metadata": {},
   "source": [
    "The data you’ll manipulate will almost always fall into one of the following categories:\n",
    "* **Vector data**  \n",
    "    2D tensors of shape (samples, features)\n",
    "* **Timeseries data or sequence data:**  \n",
    "    3D tensors of shape (samples, timesteps, features)\n",
    "* **Images—4D tensors of shape:**  \n",
    "    (samples, height, width, channels)  \n",
    "    (samples, channels, height, width)\n",
    "* **Video—5D tensors of shape:**  \n",
    "    (samples, frames, height, width, channels)  \n",
    "    (samples, frames, channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb731f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
