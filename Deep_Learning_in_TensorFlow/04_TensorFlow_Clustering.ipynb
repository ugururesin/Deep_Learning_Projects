{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c148c4",
   "metadata": {},
   "source": [
    "# TensorFlow Notebook\n",
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549109f",
   "metadata": {},
   "source": [
    "Now that we've covered regression and classification it's time to talk about clustering data!\n",
    "\n",
    "Clustering is a Machine Learning technique that involves the grouping of data points.  \n",
    "In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features.  \n",
    "(https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68)\n",
    "\n",
    "Unfortunalty there are issues with the current version of TensorFlow and the implementation for KMeans.  \n",
    "This means we cannot use KMeans without writing the algorithm from scratch.  \n",
    "We aren't quite at that level yet, so we'll just explain the basics of clustering for now.\n",
    "\n",
    "**Basic Algorithm for K-Means.**  \n",
    "Step 1: Randomly pick K points to place K centroids  \n",
    "Step 2: Assign all the data points to the centroids by distance. The closest centroid to a point is the one it is assigned to.  \n",
    "Step 3: Average all the points belonging to each centroid to find the middle of those clusters (center of mass). Place the corresponding centroids into that position.  \n",
    "Step 4: Reassign every point once again to the closest centroid.  \n",
    "Step 5: Repeat steps 3-4 until no point changes which centroid it belongs to.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376912e",
   "metadata": {},
   "source": [
    "**Hidden Markov Models**  \n",
    "\"The Hidden Markov Model is a finite set of states, each of which is associated with a (generally multidimensional) probability distribution [].  \n",
    "Transitions among the states are governed by a set of probabilities called transition probabilities.\"   \n",
    "(http://jedlik.phy.bme.hu/~gerjanos/HMM/node4.html)\n",
    "\n",
    "A hidden markov model works with probabilities to predict future events or states.  \n",
    "In this section we will learn how to create a hidden markov model that can predict the weather.\n",
    "\n",
    "This section is based on the following TensorFlow tutorial.   \n",
    "https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1355f33a",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4068eab7",
   "metadata": {},
   "source": [
    "Let's start by discussing the type of data we use when we work with a hidden markov model.\n",
    "\n",
    "In the previous sections we worked with large datasets of 100's of different entries. For a markov model we are only interested in probability distributions that have to do with states.\n",
    "\n",
    "We can find these probabilities from large datasets or may already have these values. We'll run through an example in a second that should clear some things up, but let's discuss the components of a markov model.\n",
    "\n",
    "**States:** In each markov model we have a finite set of states. These states could be something like \"warm\" and \"cold\" or \"high\" and \"low\" or even \"red\", \"green\" and \"blue\". These states are \"hidden\" within the model, which means we do not direcly observe them.\n",
    "\n",
    "**Observations:** Each state has a particular outcome or observation associated with it based on a probability distribution. An example of this is the following: On a hot day Tim has a 80% chance of being happy and a 20% chance of being sad.\n",
    "\n",
    "**Transitions:** Each state will have a probability defining the likelyhood of transitioning to a different state. An example is the following: a cold day has a 30% chance of being followed by a hot day and a 70% chance of being follwed by another cold day.\n",
    "\n",
    "To create a hidden markov model we need.  \n",
    "* States\n",
    "* Observation Distribution\n",
    "* Transition Distribution\n",
    "\n",
    "For our purpose we will assume we already have this information available as we attempt to predict the weather on a given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6cc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f48d28",
   "metadata": {},
   "source": [
    "**Weather Model**  \n",
    "\n",
    "Taken direclty from the TensorFlow documentation (https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel).\n",
    "\n",
    "We will model a simple weather system and try to predict the temperature on each day given the following information.\n",
    "\n",
    "Cold days are encoded by a 0 and hot days are encoded by a 1.\n",
    "The first day in our sequence has an 80% chance of being cold.\n",
    "A cold day has a 30% chance of being followed by a hot day.\n",
    "A hot day has a 20% chance of being followed by a cold day.\n",
    "On each day the temperature is normally distributed with mean and standard deviation 0 and 5 on a cold day and mean and standard deviation 15 and 10 on a hot day.\n",
    "If you're unfamiliar with standard deviation it can be put simply as the range of expected values.\n",
    "\n",
    "In this example, on a hot day the average temperature is 15 and ranges from 5 to 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48356591",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions  # making a shortcut for later on\n",
    "initial_distribution = tfd.Categorical(probs=[0.2, 0.8])  # Refer to point 2 above\n",
    "transition_distribution = tfd.Categorical(probs=[[0.5, 0.5],\n",
    "                                                 [0.2, 0.8]])  # refer to points 3 and 4 above\n",
    "observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.])  # refer to point 5 above\n",
    "\n",
    "# the loc argument represents the mean and the scale is the standard devitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5519d3c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensor is unhashable. Instead, use tensor.ref() as the key.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e5713e52cfbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model = tfd.HiddenMarkovModel(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0minitial_distribution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_distribution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtransition_distribution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransition_distribution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mobservation_distribution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobservation_distribution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     num_steps=7)\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py\u001b[0m in \u001b[0;36mwrapped_init\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[1;31m# called, here is the place to do it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m       \u001b[0mself_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m       \u001b[0mdefault_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m       \u001b[1;31m# Note: if we ever want to override things set in `self` by subclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m       \u001b[1;31m# `__init__`, here is the place to do it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\hidden_markov_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_distribution, transition_distribution, observation_distribution, num_steps, validate_args, allow_nan_stats, name)\u001b[0m\n\u001b[0;32m    248\u001b[0m                          \"last dimension of batch size\")\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m       self._log_init = _extract_log_probs(self._num_states,\n\u001b[0m\u001b[0;32m    251\u001b[0m                                           initial_distribution)\n\u001b[0;32m    252\u001b[0m       self._log_trans = _extract_log_probs(self._num_states,\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\hidden_markov_model.py\u001b[0m in \u001b[0;36m_extract_log_probs\u001b[1;34m(num_states, dist)\u001b[0m\n\u001b[0;32m    995\u001b[0m                                  tf.ones_like(dist.batch_shape_tensor())],\n\u001b[0;32m    996\u001b[0m                                 axis=0))\n\u001b[1;32m--> 997\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdistribution_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove_dimension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_probability\\python\\internal\\distribution_util.py\u001b[0m in \u001b[0;36mmove_dimension\u001b[1;34m(x, source_idx, dest_idx)\u001b[0m\n\u001b[0;32m    637\u001b[0m   \u001b[1;31m# One final conditional to handle the special case where source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m   \u001b[1;31m# and destination indices are equal.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m   return prefer_static.cond(tf.equal(source_idx, dest_idx),\n\u001b[0m\u001b[0;32m    640\u001b[0m                             lambda: x, x_permuted)\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_probability\\python\\internal\\prefer_static.py\u001b[0m in \u001b[0;36mcond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`false_fn` must be callable.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m   \u001b[0mpred_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_static_predicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_probability\\python\\internal\\prefer_static.py\u001b[0m in \u001b[0;36m_get_static_predicate\u001b[1;34m(pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_static_predicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m   \u001b[1;34m\"\"\"Helper function for statically evaluating predicates in `cond`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Accept 1/0 as valid boolean values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mpred_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    821\u001b[0m     if (Tensor._USE_EQUALITY and executing_eagerly_outside_functions() and\n\u001b[0;32m    822\u001b[0m         (g is None or g.building_function)):\n\u001b[1;32m--> 823\u001b[1;33m       raise TypeError(\"Tensor is unhashable. \"\n\u001b[0m\u001b[0;32m    824\u001b[0m                       \"Instead, use tensor.ref() as the key.\")\n\u001b[0;32m    825\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Tensor is unhashable. Instead, use tensor.ref() as the key."
     ]
    }
   ],
   "source": [
    "model = tfd.HiddenMarkovModel(\n",
    "    initial_distribution=initial_distribution,\n",
    "    transition_distribution=transition_distribution,\n",
    "    observation_distribution=observation_distribution,\n",
    "    num_steps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = model.mean()\n",
    "\n",
    "# due to the way TensorFlow works on a lower level we need to evaluate part of the graph\n",
    "# from within a session to see the value of this tensor\n",
    "\n",
    "# in the new version of tensorflow we need to use tf.compat.v1.Session() rather than just tf.Session()\n",
    "with tf.compat.v1.Session() as sess:  \n",
    "  print(mean.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
