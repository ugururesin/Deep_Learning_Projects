{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c611d5",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n",
    "\n",
    "#### Ugur URESIN, AI Engineer | Data Scientist\n",
    "#### Mail: uresin.ugur@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c3f665",
   "metadata": {},
   "source": [
    "The **refence** of this notebook is given:  \n",
    "https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34489f13",
   "metadata": {},
   "source": [
    "This notebook is divided into six steps as follows:\n",
    "\n",
    "* Stacked Generalization Ensemble\n",
    "* Multi-Class Classification Problem\n",
    "* Multilayer Perceptron Model\n",
    "* Train and Save Sub-Models\n",
    "* Separate Stacking Model\n",
    "* Integrated Stacking Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aebaaa",
   "metadata": {},
   "source": [
    "## Chapter 01. Stacked Generalization Ensebmle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef8a8a6",
   "metadata": {},
   "source": [
    "A model averaging ensemble combines the predictions from multiple trained models.  \n",
    "\n",
    "**Average Ensemble:** Each model contributes the same amount to the prediction regardless of how well the model performed.  \n",
    "\n",
    "**Weighted Average Ensemble:** Weighting the models based on their performance on a holdout dataset.  \n",
    "\n",
    "**Stacked Generalization (Stacking):** Replacing the linear weighted sum (e.g. linear regression) to combine the predictions of the sub-models with any learning algorithm.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10d5980",
   "metadata": {},
   "source": [
    "## Chapter 02. Multi-Class Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "525e4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTING LIBRARIES\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6f979",
   "metadata": {},
   "source": [
    "#### Creating a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d172bc",
   "metadata": {},
   "source": [
    "The scikit-learn class provides the make_blobs() function to generate dataset with the prescribed number of samples, input variables, classes, and variance of samples within a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24c77630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      " [[2.84382807 3.32650945]\n",
      " [1.9263585  4.15243012]\n",
      " [1.95204867 1.30826216]]\n",
      "y: \n",
      " [0 0 1]\n",
      "\n",
      "mean of arr, axis = None :  2.584906160501141\n",
      "\n",
      "mean of arr, axis = 0 :  [2.24074508 2.92906724]\n",
      "\n",
      "mean of arr, axis = 1 :  [3.08516876 3.03939431 1.63015542]\n"
     ]
    }
   ],
   "source": [
    "## EXAMPLE USAGE OF make_blobs()\n",
    "X, y = make_blobs(n_samples=3, centers=2, n_features=2, cluster_std=1, random_state=0)\n",
    "print(\"X: \\n\", X)\n",
    "print(\"y: \\n\", y)\n",
    "\n",
    "# mean of the flattened array \n",
    "print(\"\\nmean of arr, axis = None : \", np.mean(X)) \n",
    "    \n",
    "# mean along the axis = 0 \n",
    "print(\"\\nmean of arr, axis = 0 : \", np.mean(X, axis = 0)) \n",
    "   \n",
    "# mean along the axis = 1 \n",
    "print(\"\\nmean of arr, axis = 1 : \", np.mean(X, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b95b4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23027e02",
   "metadata": {},
   "source": [
    "#### Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36d8e9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "\n",
    "# scatter plot, dots colored by class value\n",
    "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'red', 1:'blue', 2:'green'}\n",
    "fig, ax = pyplot.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dfb628",
   "metadata": {},
   "source": [
    "## Chapter 03. Multilayer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eb29a6",
   "metadata": {},
   "source": [
    "* Let's create a dataset with 1,100 points.  \n",
    "* The model will be trained on the first 100 points and the remaining 1,000 will be held back in a test dataset, unavailable to the model.  \n",
    "* The problem is a multi-class classification problem, and we will model it using a softmax activation function on the output layer. \n",
    "* This means that the model will predict a vector with three elements with the probability that the sample belongs to each of the three classes.\n",
    "* Therefore, we must one hot encode the class values before we split the rows into the train and test datasets. We can do this using the Keras to_categorical() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507339b",
   "metadata": {},
   "source": [
    "#### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3c3e6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2) (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "\n",
    "# one hot encode output variable\n",
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "print(trainX.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65f265",
   "metadata": {},
   "source": [
    "#### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8461c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "## MODEL DEFINITION\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcbadfd",
   "metadata": {},
   "source": [
    "#### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45e29871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.0963 - accuracy: 0.4100 - val_loss: 1.0996 - val_accuracy: 0.3790\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0549 - accuracy: 0.4300 - val_loss: 1.0557 - val_accuracy: 0.3850\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0134 - accuracy: 0.4300 - val_loss: 1.0234 - val_accuracy: 0.3900\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9852 - accuracy: 0.4300 - val_loss: 0.9995 - val_accuracy: 0.3910\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9672 - accuracy: 0.4300 - val_loss: 0.9802 - val_accuracy: 0.3920\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9490 - accuracy: 0.4300 - val_loss: 0.9655 - val_accuracy: 0.3980\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9347 - accuracy: 0.4400 - val_loss: 0.9514 - val_accuracy: 0.4020\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9192 - accuracy: 0.4300 - val_loss: 0.9371 - val_accuracy: 0.4070\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9031 - accuracy: 0.4400 - val_loss: 0.9243 - val_accuracy: 0.4220\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8889 - accuracy: 0.4700 - val_loss: 0.9122 - val_accuracy: 0.4410\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8743 - accuracy: 0.5000 - val_loss: 0.9007 - val_accuracy: 0.4500\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8602 - accuracy: 0.5200 - val_loss: 0.8901 - val_accuracy: 0.4580\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8473 - accuracy: 0.5300 - val_loss: 0.8806 - val_accuracy: 0.4640\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8358 - accuracy: 0.5500 - val_loss: 0.8729 - val_accuracy: 0.4700\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8246 - accuracy: 0.5600 - val_loss: 0.8653 - val_accuracy: 0.4830\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8143 - accuracy: 0.5700 - val_loss: 0.8573 - val_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8049 - accuracy: 0.5700 - val_loss: 0.8482 - val_accuracy: 0.5130\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7948 - accuracy: 0.5800 - val_loss: 0.8398 - val_accuracy: 0.5240\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7858 - accuracy: 0.5900 - val_loss: 0.8316 - val_accuracy: 0.5310\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7768 - accuracy: 0.6000 - val_loss: 0.8231 - val_accuracy: 0.5460\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7689 - accuracy: 0.6000 - val_loss: 0.8152 - val_accuracy: 0.5610\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7605 - accuracy: 0.6100 - val_loss: 0.8077 - val_accuracy: 0.5670\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7542 - accuracy: 0.6400 - val_loss: 0.8008 - val_accuracy: 0.5790\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7459 - accuracy: 0.6300 - val_loss: 0.7947 - val_accuracy: 0.5840\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7387 - accuracy: 0.6300 - val_loss: 0.7877 - val_accuracy: 0.5940\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7315 - accuracy: 0.6400 - val_loss: 0.7821 - val_accuracy: 0.5970\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7243 - accuracy: 0.6400 - val_loss: 0.7762 - val_accuracy: 0.6100\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7169 - accuracy: 0.6500 - val_loss: 0.7696 - val_accuracy: 0.6180\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7101 - accuracy: 0.6800 - val_loss: 0.7628 - val_accuracy: 0.6390\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7037 - accuracy: 0.7000 - val_loss: 0.7569 - val_accuracy: 0.6450\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6976 - accuracy: 0.7000 - val_loss: 0.7521 - val_accuracy: 0.6530\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6918 - accuracy: 0.7100 - val_loss: 0.7488 - val_accuracy: 0.6520\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6866 - accuracy: 0.6900 - val_loss: 0.7452 - val_accuracy: 0.6530\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6813 - accuracy: 0.7100 - val_loss: 0.7388 - val_accuracy: 0.6660\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6760 - accuracy: 0.7200 - val_loss: 0.7329 - val_accuracy: 0.6710\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6705 - accuracy: 0.7300 - val_loss: 0.7278 - val_accuracy: 0.6790\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6652 - accuracy: 0.7300 - val_loss: 0.7237 - val_accuracy: 0.6800\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6609 - accuracy: 0.7300 - val_loss: 0.7186 - val_accuracy: 0.6820\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6564 - accuracy: 0.7300 - val_loss: 0.7137 - val_accuracy: 0.6840\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6513 - accuracy: 0.7400 - val_loss: 0.7077 - val_accuracy: 0.6880\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6482 - accuracy: 0.7300 - val_loss: 0.7019 - val_accuracy: 0.6950\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6466 - accuracy: 0.7100 - val_loss: 0.6980 - val_accuracy: 0.6990\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6427 - accuracy: 0.7000 - val_loss: 0.6949 - val_accuracy: 0.7010\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6398 - accuracy: 0.7000 - val_loss: 0.6919 - val_accuracy: 0.7030\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6362 - accuracy: 0.7000 - val_loss: 0.6889 - val_accuracy: 0.7100\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6356 - accuracy: 0.7200 - val_loss: 0.6858 - val_accuracy: 0.7190\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6306 - accuracy: 0.7300 - val_loss: 0.6826 - val_accuracy: 0.7160\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6251 - accuracy: 0.7200 - val_loss: 0.6824 - val_accuracy: 0.7050\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6212 - accuracy: 0.7500 - val_loss: 0.6814 - val_accuracy: 0.7100\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6181 - accuracy: 0.7500 - val_loss: 0.6793 - val_accuracy: 0.7080\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6154 - accuracy: 0.7400 - val_loss: 0.6771 - val_accuracy: 0.7090\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6126 - accuracy: 0.7400 - val_loss: 0.6745 - val_accuracy: 0.7090\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6096 - accuracy: 0.7400 - val_loss: 0.6709 - val_accuracy: 0.7130\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6068 - accuracy: 0.7400 - val_loss: 0.6669 - val_accuracy: 0.7190\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6040 - accuracy: 0.7500 - val_loss: 0.6654 - val_accuracy: 0.7190\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6006 - accuracy: 0.7400 - val_loss: 0.6666 - val_accuracy: 0.7140\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6012 - accuracy: 0.7200 - val_loss: 0.6665 - val_accuracy: 0.7110\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5986 - accuracy: 0.7200 - val_loss: 0.6623 - val_accuracy: 0.7130\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5945 - accuracy: 0.7400 - val_loss: 0.6565 - val_accuracy: 0.7210\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5912 - accuracy: 0.7600 - val_loss: 0.6519 - val_accuracy: 0.7240\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5883 - accuracy: 0.7500 - val_loss: 0.6495 - val_accuracy: 0.7250\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5849 - accuracy: 0.7400 - val_loss: 0.6475 - val_accuracy: 0.7320\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5834 - accuracy: 0.7400 - val_loss: 0.6446 - val_accuracy: 0.7360\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5805 - accuracy: 0.7300 - val_loss: 0.6423 - val_accuracy: 0.7370\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5779 - accuracy: 0.7300 - val_loss: 0.6392 - val_accuracy: 0.7450\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5759 - accuracy: 0.7300 - val_loss: 0.6367 - val_accuracy: 0.7500\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5803 - accuracy: 0.7600 - val_loss: 0.6350 - val_accuracy: 0.7490\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5784 - accuracy: 0.7500 - val_loss: 0.6329 - val_accuracy: 0.7510\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5760 - accuracy: 0.7500 - val_loss: 0.6306 - val_accuracy: 0.7500\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5731 - accuracy: 0.7600 - val_loss: 0.6283 - val_accuracy: 0.7530\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5710 - accuracy: 0.7500 - val_loss: 0.6254 - val_accuracy: 0.7560\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5671 - accuracy: 0.7600 - val_loss: 0.6233 - val_accuracy: 0.7580\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5631 - accuracy: 0.7500 - val_loss: 0.6216 - val_accuracy: 0.7560\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5592 - accuracy: 0.7500 - val_loss: 0.6206 - val_accuracy: 0.7530\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5559 - accuracy: 0.7400 - val_loss: 0.6197 - val_accuracy: 0.7470\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5538 - accuracy: 0.7600 - val_loss: 0.6183 - val_accuracy: 0.7460\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5520 - accuracy: 0.7600 - val_loss: 0.6184 - val_accuracy: 0.7400\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5512 - accuracy: 0.7700 - val_loss: 0.6185 - val_accuracy: 0.7360\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5494 - accuracy: 0.7700 - val_loss: 0.6174 - val_accuracy: 0.7370\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5472 - accuracy: 0.7700 - val_loss: 0.6146 - val_accuracy: 0.7390\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5448 - accuracy: 0.7700 - val_loss: 0.6131 - val_accuracy: 0.7380\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5434 - accuracy: 0.7700 - val_loss: 0.6122 - val_accuracy: 0.7370\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5423 - accuracy: 0.7700 - val_loss: 0.6111 - val_accuracy: 0.7350\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5400 - accuracy: 0.7700 - val_loss: 0.6085 - val_accuracy: 0.7380\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5376 - accuracy: 0.7700 - val_loss: 0.6040 - val_accuracy: 0.7450\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7800 - val_loss: 0.5989 - val_accuracy: 0.7550\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5332 - accuracy: 0.7700 - val_loss: 0.5954 - val_accuracy: 0.7640\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5325 - accuracy: 0.7600 - val_loss: 0.5930 - val_accuracy: 0.7680\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5332 - accuracy: 0.7800 - val_loss: 0.5914 - val_accuracy: 0.7660\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5317 - accuracy: 0.7800 - val_loss: 0.5901 - val_accuracy: 0.7680\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5290 - accuracy: 0.7800 - val_loss: 0.5889 - val_accuracy: 0.7700\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5249 - accuracy: 0.7700 - val_loss: 0.5892 - val_accuracy: 0.7610\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5245 - accuracy: 0.7800 - val_loss: 0.5904 - val_accuracy: 0.7510\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5226 - accuracy: 0.7900 - val_loss: 0.5904 - val_accuracy: 0.7520\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5204 - accuracy: 0.7900 - val_loss: 0.5887 - val_accuracy: 0.7530\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5188 - accuracy: 0.7900 - val_loss: 0.5877 - val_accuracy: 0.7530\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5174 - accuracy: 0.7900 - val_loss: 0.5858 - val_accuracy: 0.7530\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5156 - accuracy: 0.8000 - val_loss: 0.5834 - val_accuracy: 0.7550\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5138 - accuracy: 0.8000 - val_loss: 0.5825 - val_accuracy: 0.7550\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5125 - accuracy: 0.8000 - val_loss: 0.5808 - val_accuracy: 0.7550\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5108 - accuracy: 0.8000 - val_loss: 0.5791 - val_accuracy: 0.7540\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5093 - accuracy: 0.8000 - val_loss: 0.5769 - val_accuracy: 0.7570\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5082 - accuracy: 0.7900 - val_loss: 0.5740 - val_accuracy: 0.7620\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5066 - accuracy: 0.7900 - val_loss: 0.5717 - val_accuracy: 0.7620\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5061 - accuracy: 0.7900 - val_loss: 0.5680 - val_accuracy: 0.7710\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5044 - accuracy: 0.7700 - val_loss: 0.5649 - val_accuracy: 0.7760\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.7700 - val_loss: 0.5632 - val_accuracy: 0.7770\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5001 - accuracy: 0.7700 - val_loss: 0.5632 - val_accuracy: 0.7730\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4990 - accuracy: 0.7700 - val_loss: 0.5632 - val_accuracy: 0.7650\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4963 - accuracy: 0.7900 - val_loss: 0.5601 - val_accuracy: 0.7740\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4940 - accuracy: 0.7700 - val_loss: 0.5575 - val_accuracy: 0.7780\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4923 - accuracy: 0.7700 - val_loss: 0.5553 - val_accuracy: 0.7790\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4909 - accuracy: 0.7800 - val_loss: 0.5545 - val_accuracy: 0.7820\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4883 - accuracy: 0.7700 - val_loss: 0.5564 - val_accuracy: 0.7670\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.7900 - val_loss: 0.5578 - val_accuracy: 0.7650\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4875 - accuracy: 0.7900 - val_loss: 0.5563 - val_accuracy: 0.7650\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4858 - accuracy: 0.7900 - val_loss: 0.5523 - val_accuracy: 0.7700\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4845 - accuracy: 0.7900 - val_loss: 0.5486 - val_accuracy: 0.7780\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4821 - accuracy: 0.8000 - val_loss: 0.5473 - val_accuracy: 0.7790\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4805 - accuracy: 0.8000 - val_loss: 0.5450 - val_accuracy: 0.7810\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4790 - accuracy: 0.8000 - val_loss: 0.5430 - val_accuracy: 0.7810\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4782 - accuracy: 0.8100 - val_loss: 0.5424 - val_accuracy: 0.7810\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4771 - accuracy: 0.8100 - val_loss: 0.5412 - val_accuracy: 0.7810\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4758 - accuracy: 0.8100 - val_loss: 0.5407 - val_accuracy: 0.7800\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4751 - accuracy: 0.8000 - val_loss: 0.5387 - val_accuracy: 0.7840\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4731 - accuracy: 0.8000 - val_loss: 0.5366 - val_accuracy: 0.7860\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.8000 - val_loss: 0.5363 - val_accuracy: 0.7840\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.8000 - val_loss: 0.5344 - val_accuracy: 0.7850\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.8000 - val_loss: 0.5327 - val_accuracy: 0.7860\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.8000 - val_loss: 0.5327 - val_accuracy: 0.7860\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.8000 - val_loss: 0.5319 - val_accuracy: 0.7870\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4658 - accuracy: 0.8200 - val_loss: 0.5315 - val_accuracy: 0.7870\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.8200 - val_loss: 0.5302 - val_accuracy: 0.7870\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.8200 - val_loss: 0.5310 - val_accuracy: 0.7860\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.8200 - val_loss: 0.5319 - val_accuracy: 0.7810\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4622 - accuracy: 0.8200 - val_loss: 0.5322 - val_accuracy: 0.7800\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.8200 - val_loss: 0.5310 - val_accuracy: 0.7820\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4599 - accuracy: 0.8100 - val_loss: 0.5291 - val_accuracy: 0.7830\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.8100 - val_loss: 0.5288 - val_accuracy: 0.7800\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.8000 - val_loss: 0.5288 - val_accuracy: 0.7790\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.8000 - val_loss: 0.5258 - val_accuracy: 0.7830\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4557 - accuracy: 0.8000 - val_loss: 0.5234 - val_accuracy: 0.7850\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.8100 - val_loss: 0.5192 - val_accuracy: 0.7890\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4523 - accuracy: 0.8100 - val_loss: 0.5146 - val_accuracy: 0.7940\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4526 - accuracy: 0.8100 - val_loss: 0.5121 - val_accuracy: 0.7970\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4527 - accuracy: 0.8200 - val_loss: 0.5104 - val_accuracy: 0.7970\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.8000 - val_loss: 0.5096 - val_accuracy: 0.7970\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4510 - accuracy: 0.8100 - val_loss: 0.5093 - val_accuracy: 0.7970\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.8100 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.8000 - val_loss: 0.5119 - val_accuracy: 0.7950\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.8100 - val_loss: 0.5127 - val_accuracy: 0.7920\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4464 - accuracy: 0.8100 - val_loss: 0.5161 - val_accuracy: 0.7860\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.8100 - val_loss: 0.5162 - val_accuracy: 0.7860\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4450 - accuracy: 0.8100 - val_loss: 0.5163 - val_accuracy: 0.7850\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.8100 - val_loss: 0.5152 - val_accuracy: 0.7830\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.8100 - val_loss: 0.5140 - val_accuracy: 0.7850\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.8100 - val_loss: 0.5125 - val_accuracy: 0.7860\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.8100 - val_loss: 0.5103 - val_accuracy: 0.7920\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.8000 - val_loss: 0.5060 - val_accuracy: 0.7920\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.8000 - val_loss: 0.5042 - val_accuracy: 0.7950\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.8100 - val_loss: 0.5039 - val_accuracy: 0.7940\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.8100 - val_loss: 0.5040 - val_accuracy: 0.7930\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8100 - val_loss: 0.5053 - val_accuracy: 0.7950\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4332 - accuracy: 0.8000 - val_loss: 0.5068 - val_accuracy: 0.7960\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4329 - accuracy: 0.8000 - val_loss: 0.5090 - val_accuracy: 0.7950\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.8100 - val_loss: 0.5119 - val_accuracy: 0.7920\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.8200 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.8200 - val_loss: 0.5082 - val_accuracy: 0.7960\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.8100 - val_loss: 0.5043 - val_accuracy: 0.7950\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8000 - val_loss: 0.5012 - val_accuracy: 0.7950\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.8100 - val_loss: 0.4987 - val_accuracy: 0.7950\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.8100 - val_loss: 0.4967 - val_accuracy: 0.7950\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.8100 - val_loss: 0.4952 - val_accuracy: 0.7950\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.8100 - val_loss: 0.4954 - val_accuracy: 0.7940\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4245 - accuracy: 0.8100 - val_loss: 0.4945 - val_accuracy: 0.7940\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.8100 - val_loss: 0.4936 - val_accuracy: 0.7960\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8100 - val_loss: 0.4918 - val_accuracy: 0.7980\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8100 - val_loss: 0.4897 - val_accuracy: 0.8030\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4226 - accuracy: 0.8100 - val_loss: 0.4887 - val_accuracy: 0.8030\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4225 - accuracy: 0.8100 - val_loss: 0.4882 - val_accuracy: 0.8030\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4226 - accuracy: 0.8200 - val_loss: 0.4886 - val_accuracy: 0.8030\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4208 - accuracy: 0.8100 - val_loss: 0.4889 - val_accuracy: 0.8010\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8100 - val_loss: 0.4901 - val_accuracy: 0.7970\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8100 - val_loss: 0.4914 - val_accuracy: 0.7950\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.8200 - val_loss: 0.4915 - val_accuracy: 0.7950\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4182 - accuracy: 0.8200 - val_loss: 0.4896 - val_accuracy: 0.7960\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.8100 - val_loss: 0.4888 - val_accuracy: 0.7960\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8200 - val_loss: 0.4900 - val_accuracy: 0.7970\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8100 - val_loss: 0.4901 - val_accuracy: 0.7970\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8100 - val_loss: 0.4884 - val_accuracy: 0.7970\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8100 - val_loss: 0.4870 - val_accuracy: 0.7970\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8100 - val_loss: 0.4845 - val_accuracy: 0.7990\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8000 - val_loss: 0.4815 - val_accuracy: 0.8010\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8100 - val_loss: 0.4802 - val_accuracy: 0.8040\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4111 - accuracy: 0.8100 - val_loss: 0.4796 - val_accuracy: 0.8070\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8100 - val_loss: 0.4796 - val_accuracy: 0.8050\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8100 - val_loss: 0.4795 - val_accuracy: 0.8070\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8100 - val_loss: 0.4798 - val_accuracy: 0.8070\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8100 - val_loss: 0.4800 - val_accuracy: 0.8070\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4081 - accuracy: 0.8200 - val_loss: 0.4805 - val_accuracy: 0.8080\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.8000 - val_loss: 0.4804 - val_accuracy: 0.8060\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8100 - val_loss: 0.4796 - val_accuracy: 0.8030\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.8000 - val_loss: 0.4792 - val_accuracy: 0.8010\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4076 - accuracy: 0.8000 - val_loss: 0.4791 - val_accuracy: 0.8020\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4073 - accuracy: 0.8000 - val_loss: 0.4788 - val_accuracy: 0.8020\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4058 - accuracy: 0.8000 - val_loss: 0.4793 - val_accuracy: 0.8030\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8100 - val_loss: 0.4807 - val_accuracy: 0.7970\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8000 - val_loss: 0.4835 - val_accuracy: 0.7940\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8000 - val_loss: 0.4853 - val_accuracy: 0.7920\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8100 - val_loss: 0.4845 - val_accuracy: 0.7910\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.8100 - val_loss: 0.4870 - val_accuracy: 0.7890\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8200 - val_loss: 0.4887 - val_accuracy: 0.7890\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8200 - val_loss: 0.4891 - val_accuracy: 0.7900\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8200 - val_loss: 0.4886 - val_accuracy: 0.7910\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8200 - val_loss: 0.4848 - val_accuracy: 0.7970\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3996 - accuracy: 0.8100 - val_loss: 0.4821 - val_accuracy: 0.8000\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8000 - val_loss: 0.4803 - val_accuracy: 0.8020\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8200 - val_loss: 0.4790 - val_accuracy: 0.8020\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8200 - val_loss: 0.4762 - val_accuracy: 0.8050\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8300 - val_loss: 0.4746 - val_accuracy: 0.8110\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8200 - val_loss: 0.4739 - val_accuracy: 0.8110\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3971 - accuracy: 0.8200 - val_loss: 0.4736 - val_accuracy: 0.8110\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8200 - val_loss: 0.4742 - val_accuracy: 0.8110\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8200 - val_loss: 0.4740 - val_accuracy: 0.8060\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3939 - accuracy: 0.8200 - val_loss: 0.4753 - val_accuracy: 0.7990\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3940 - accuracy: 0.8200 - val_loss: 0.4776 - val_accuracy: 0.8040\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3942 - accuracy: 0.8300 - val_loss: 0.4782 - val_accuracy: 0.7990\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8300 - val_loss: 0.4771 - val_accuracy: 0.8010\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8300 - val_loss: 0.4725 - val_accuracy: 0.8060\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8200 - val_loss: 0.4696 - val_accuracy: 0.8090\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8200 - val_loss: 0.4684 - val_accuracy: 0.8100\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8200 - val_loss: 0.4682 - val_accuracy: 0.8100\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8100 - val_loss: 0.4680 - val_accuracy: 0.8110\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8200 - val_loss: 0.4680 - val_accuracy: 0.8110\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8200 - val_loss: 0.4675 - val_accuracy: 0.8110\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8200 - val_loss: 0.4675 - val_accuracy: 0.8100\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8200 - val_loss: 0.4684 - val_accuracy: 0.8090\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8200 - val_loss: 0.4722 - val_accuracy: 0.8020\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8200 - val_loss: 0.4741 - val_accuracy: 0.7980\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.8200 - val_loss: 0.4761 - val_accuracy: 0.7940\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8100 - val_loss: 0.4737 - val_accuracy: 0.7960\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8200 - val_loss: 0.4706 - val_accuracy: 0.7970\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8200 - val_loss: 0.4693 - val_accuracy: 0.7990\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8100 - val_loss: 0.4687 - val_accuracy: 0.7980\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3869 - accuracy: 0.8100 - val_loss: 0.4658 - val_accuracy: 0.8050\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3854 - accuracy: 0.8000 - val_loss: 0.4647 - val_accuracy: 0.8050\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3852 - accuracy: 0.8000 - val_loss: 0.4641 - val_accuracy: 0.8050\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3848 - accuracy: 0.8000 - val_loss: 0.4634 - val_accuracy: 0.8060\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8000 - val_loss: 0.4632 - val_accuracy: 0.8070\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8000 - val_loss: 0.4637 - val_accuracy: 0.8070\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3837 - accuracy: 0.8000 - val_loss: 0.4632 - val_accuracy: 0.8070\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.8000 - val_loss: 0.4627 - val_accuracy: 0.8080\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8100 - val_loss: 0.4624 - val_accuracy: 0.8060\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8100 - val_loss: 0.4636 - val_accuracy: 0.8030\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8200 - val_loss: 0.4635 - val_accuracy: 0.8030\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8200 - val_loss: 0.4623 - val_accuracy: 0.8060\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.8100 - val_loss: 0.4611 - val_accuracy: 0.8090\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.8000 - val_loss: 0.4604 - val_accuracy: 0.8110\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.8000 - val_loss: 0.4595 - val_accuracy: 0.8140\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3790 - accuracy: 0.8200 - val_loss: 0.4588 - val_accuracy: 0.8150\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.8300 - val_loss: 0.4583 - val_accuracy: 0.8190\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.8200 - val_loss: 0.4583 - val_accuracy: 0.8220\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8200 - val_loss: 0.4593 - val_accuracy: 0.8230\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8200 - val_loss: 0.4607 - val_accuracy: 0.8190\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8200 - val_loss: 0.4617 - val_accuracy: 0.8130\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3769 - accuracy: 0.8400 - val_loss: 0.4626 - val_accuracy: 0.8120\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3773 - accuracy: 0.8400 - val_loss: 0.4626 - val_accuracy: 0.8090\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3764 - accuracy: 0.8200 - val_loss: 0.4608 - val_accuracy: 0.8100\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3762 - accuracy: 0.8200 - val_loss: 0.4601 - val_accuracy: 0.8120\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3756 - accuracy: 0.8200 - val_loss: 0.4604 - val_accuracy: 0.8100\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8200 - val_loss: 0.4616 - val_accuracy: 0.8110\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8200 - val_loss: 0.4613 - val_accuracy: 0.8110\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8200 - val_loss: 0.4603 - val_accuracy: 0.8120\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8200 - val_loss: 0.4596 - val_accuracy: 0.8160\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8200 - val_loss: 0.4590 - val_accuracy: 0.8160\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8100 - val_loss: 0.4586 - val_accuracy: 0.8170\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8100 - val_loss: 0.4594 - val_accuracy: 0.8140\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8100 - val_loss: 0.4604 - val_accuracy: 0.8130\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8000 - val_loss: 0.4609 - val_accuracy: 0.8100\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3713 - accuracy: 0.8000 - val_loss: 0.4615 - val_accuracy: 0.8040\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8100 - val_loss: 0.4621 - val_accuracy: 0.8060\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8200 - val_loss: 0.4629 - val_accuracy: 0.8020\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3714 - accuracy: 0.8200 - val_loss: 0.4632 - val_accuracy: 0.8010\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3709 - accuracy: 0.8200 - val_loss: 0.4630 - val_accuracy: 0.8010\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8200 - val_loss: 0.4626 - val_accuracy: 0.8000\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3702 - accuracy: 0.8200 - val_loss: 0.4614 - val_accuracy: 0.8040\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3689 - accuracy: 0.8200 - val_loss: 0.4596 - val_accuracy: 0.8080\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3692 - accuracy: 0.8200 - val_loss: 0.4584 - val_accuracy: 0.8070\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3687 - accuracy: 0.8300 - val_loss: 0.4592 - val_accuracy: 0.8050\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3683 - accuracy: 0.8400 - val_loss: 0.4586 - val_accuracy: 0.8050\n",
      "Epoch 291/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3680 - accuracy: 0.8400 - val_loss: 0.4572 - val_accuracy: 0.8090\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3674 - accuracy: 0.8100 - val_loss: 0.4558 - val_accuracy: 0.8160\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3675 - accuracy: 0.8300 - val_loss: 0.4535 - val_accuracy: 0.8190\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8200 - val_loss: 0.4522 - val_accuracy: 0.8160\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3665 - accuracy: 0.8100 - val_loss: 0.4518 - val_accuracy: 0.8200\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3677 - accuracy: 0.8200 - val_loss: 0.4520 - val_accuracy: 0.8240\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8200 - val_loss: 0.4526 - val_accuracy: 0.8260\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3678 - accuracy: 0.8100 - val_loss: 0.4541 - val_accuracy: 0.8250\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3671 - accuracy: 0.8200 - val_loss: 0.4546 - val_accuracy: 0.8250\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8200 - val_loss: 0.4549 - val_accuracy: 0.8280\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.8200 - val_loss: 0.4555 - val_accuracy: 0.8260\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8200 - val_loss: 0.4568 - val_accuracy: 0.8210\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8200 - val_loss: 0.4580 - val_accuracy: 0.8190\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8200 - val_loss: 0.4579 - val_accuracy: 0.8190\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3648 - accuracy: 0.8200 - val_loss: 0.4571 - val_accuracy: 0.8190\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3643 - accuracy: 0.8200 - val_loss: 0.4572 - val_accuracy: 0.8170\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3641 - accuracy: 0.8200 - val_loss: 0.4570 - val_accuracy: 0.8130\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3634 - accuracy: 0.8200 - val_loss: 0.4568 - val_accuracy: 0.8120\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3633 - accuracy: 0.8200 - val_loss: 0.4560 - val_accuracy: 0.8160\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3637 - accuracy: 0.8200 - val_loss: 0.4544 - val_accuracy: 0.8210\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3628 - accuracy: 0.8100 - val_loss: 0.4542 - val_accuracy: 0.8170\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3620 - accuracy: 0.8300 - val_loss: 0.4546 - val_accuracy: 0.8140\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3618 - accuracy: 0.8200 - val_loss: 0.4549 - val_accuracy: 0.8090\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8300 - val_loss: 0.4565 - val_accuracy: 0.8080\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3641 - accuracy: 0.8300 - val_loss: 0.4583 - val_accuracy: 0.8010\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3649 - accuracy: 0.8200 - val_loss: 0.4588 - val_accuracy: 0.7980\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8300 - val_loss: 0.4593 - val_accuracy: 0.8010\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8300 - val_loss: 0.4609 - val_accuracy: 0.7990\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3615 - accuracy: 0.8300 - val_loss: 0.4626 - val_accuracy: 0.7970\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8300 - val_loss: 0.4633 - val_accuracy: 0.7980\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8300 - val_loss: 0.4610 - val_accuracy: 0.7990\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.8200 - val_loss: 0.4595 - val_accuracy: 0.7990\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3611 - accuracy: 0.8300 - val_loss: 0.4583 - val_accuracy: 0.8000\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3602 - accuracy: 0.8300 - val_loss: 0.4576 - val_accuracy: 0.8090\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3597 - accuracy: 0.8300 - val_loss: 0.4573 - val_accuracy: 0.8110\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3584 - accuracy: 0.8200 - val_loss: 0.4545 - val_accuracy: 0.8100\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3584 - accuracy: 0.8300 - val_loss: 0.4532 - val_accuracy: 0.8150\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3594 - accuracy: 0.8300 - val_loss: 0.4527 - val_accuracy: 0.8150\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3583 - accuracy: 0.8200 - val_loss: 0.4532 - val_accuracy: 0.8140\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3580 - accuracy: 0.8100 - val_loss: 0.4533 - val_accuracy: 0.8180\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3570 - accuracy: 0.8200 - val_loss: 0.4520 - val_accuracy: 0.8160\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3567 - accuracy: 0.8400 - val_loss: 0.4520 - val_accuracy: 0.8190\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3571 - accuracy: 0.8300 - val_loss: 0.4521 - val_accuracy: 0.8190\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3566 - accuracy: 0.8300 - val_loss: 0.4525 - val_accuracy: 0.8180\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3558 - accuracy: 0.8400 - val_loss: 0.4528 - val_accuracy: 0.8180\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3569 - accuracy: 0.8200 - val_loss: 0.4527 - val_accuracy: 0.8130\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3554 - accuracy: 0.8100 - val_loss: 0.4539 - val_accuracy: 0.8130\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3553 - accuracy: 0.8200 - val_loss: 0.4547 - val_accuracy: 0.8120\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3556 - accuracy: 0.8200 - val_loss: 0.4553 - val_accuracy: 0.8120\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3553 - accuracy: 0.8300 - val_loss: 0.4554 - val_accuracy: 0.8120\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3551 - accuracy: 0.8200 - val_loss: 0.4547 - val_accuracy: 0.8130\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3546 - accuracy: 0.8200 - val_loss: 0.4532 - val_accuracy: 0.8120\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3545 - accuracy: 0.8200 - val_loss: 0.4516 - val_accuracy: 0.8200\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3564 - accuracy: 0.8300 - val_loss: 0.4513 - val_accuracy: 0.8230\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8300 - val_loss: 0.4509 - val_accuracy: 0.8260\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3573 - accuracy: 0.8300 - val_loss: 0.4508 - val_accuracy: 0.8230\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3563 - accuracy: 0.8300 - val_loss: 0.4507 - val_accuracy: 0.8190\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3552 - accuracy: 0.8200 - val_loss: 0.4513 - val_accuracy: 0.8170\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3539 - accuracy: 0.8200 - val_loss: 0.4530 - val_accuracy: 0.8160\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3540 - accuracy: 0.8100 - val_loss: 0.4563 - val_accuracy: 0.8180\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3535 - accuracy: 0.8300 - val_loss: 0.4577 - val_accuracy: 0.8130\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3552 - accuracy: 0.8300 - val_loss: 0.4584 - val_accuracy: 0.8150\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3545 - accuracy: 0.8300 - val_loss: 0.4578 - val_accuracy: 0.8130\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3538 - accuracy: 0.8200 - val_loss: 0.4577 - val_accuracy: 0.8120\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3539 - accuracy: 0.8200 - val_loss: 0.4585 - val_accuracy: 0.8120\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3539 - accuracy: 0.8300 - val_loss: 0.4590 - val_accuracy: 0.8120\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3539 - accuracy: 0.8300 - val_loss: 0.4594 - val_accuracy: 0.8120\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3539 - accuracy: 0.8300 - val_loss: 0.4580 - val_accuracy: 0.8150\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3528 - accuracy: 0.8300 - val_loss: 0.4568 - val_accuracy: 0.8170\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3519 - accuracy: 0.8300 - val_loss: 0.4565 - val_accuracy: 0.8170\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.8200 - val_loss: 0.4565 - val_accuracy: 0.8180\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3505 - accuracy: 0.8200 - val_loss: 0.4569 - val_accuracy: 0.8170\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3505 - accuracy: 0.8300 - val_loss: 0.4571 - val_accuracy: 0.8170\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3503 - accuracy: 0.8300 - val_loss: 0.4568 - val_accuracy: 0.8170\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3501 - accuracy: 0.8200 - val_loss: 0.4564 - val_accuracy: 0.8160\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3492 - accuracy: 0.8200 - val_loss: 0.4558 - val_accuracy: 0.8130\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3490 - accuracy: 0.8300 - val_loss: 0.4558 - val_accuracy: 0.8130\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3490 - accuracy: 0.8300 - val_loss: 0.4564 - val_accuracy: 0.8060\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3491 - accuracy: 0.8300 - val_loss: 0.4568 - val_accuracy: 0.8030\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3491 - accuracy: 0.8300 - val_loss: 0.4566 - val_accuracy: 0.8020\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3506 - accuracy: 0.8300 - val_loss: 0.4549 - val_accuracy: 0.8050\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3489 - accuracy: 0.8300 - val_loss: 0.4553 - val_accuracy: 0.8050\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3485 - accuracy: 0.8300 - val_loss: 0.4558 - val_accuracy: 0.8040\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.8200 - val_loss: 0.4555 - val_accuracy: 0.8040\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3480 - accuracy: 0.8200 - val_loss: 0.4557 - val_accuracy: 0.8050\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3480 - accuracy: 0.8200 - val_loss: 0.4558 - val_accuracy: 0.8030\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3478 - accuracy: 0.8200 - val_loss: 0.4566 - val_accuracy: 0.8040\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3477 - accuracy: 0.8200 - val_loss: 0.4590 - val_accuracy: 0.8060\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3483 - accuracy: 0.8300 - val_loss: 0.4597 - val_accuracy: 0.8060\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3487 - accuracy: 0.8400 - val_loss: 0.4600 - val_accuracy: 0.8010\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.8400 - val_loss: 0.4594 - val_accuracy: 0.8020\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3485 - accuracy: 0.8400 - val_loss: 0.4604 - val_accuracy: 0.8020\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3486 - accuracy: 0.8400 - val_loss: 0.4594 - val_accuracy: 0.8080\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8300 - val_loss: 0.4588 - val_accuracy: 0.8080\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3479 - accuracy: 0.8300 - val_loss: 0.4590 - val_accuracy: 0.8090\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3474 - accuracy: 0.8300 - val_loss: 0.4574 - val_accuracy: 0.8100\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3466 - accuracy: 0.8300 - val_loss: 0.4556 - val_accuracy: 0.8120\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3458 - accuracy: 0.8300 - val_loss: 0.4540 - val_accuracy: 0.8130\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3456 - accuracy: 0.8200 - val_loss: 0.4530 - val_accuracy: 0.8120\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3448 - accuracy: 0.8100 - val_loss: 0.4527 - val_accuracy: 0.8150\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3441 - accuracy: 0.8100 - val_loss: 0.4531 - val_accuracy: 0.8130\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3441 - accuracy: 0.8300 - val_loss: 0.4535 - val_accuracy: 0.8110\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3452 - accuracy: 0.8400 - val_loss: 0.4549 - val_accuracy: 0.8020\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3462 - accuracy: 0.8400 - val_loss: 0.4564 - val_accuracy: 0.8000\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3453 - accuracy: 0.8400 - val_loss: 0.4585 - val_accuracy: 0.7980\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3462 - accuracy: 0.8400 - val_loss: 0.4604 - val_accuracy: 0.7970\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3465 - accuracy: 0.8500 - val_loss: 0.4607 - val_accuracy: 0.7960\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3463 - accuracy: 0.8500 - val_loss: 0.4598 - val_accuracy: 0.7980\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3459 - accuracy: 0.8400 - val_loss: 0.4577 - val_accuracy: 0.7990\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3447 - accuracy: 0.8200 - val_loss: 0.4573 - val_accuracy: 0.8010\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3445 - accuracy: 0.8300 - val_loss: 0.4586 - val_accuracy: 0.8020\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3441 - accuracy: 0.8300 - val_loss: 0.4577 - val_accuracy: 0.8010\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3436 - accuracy: 0.8200 - val_loss: 0.4565 - val_accuracy: 0.8050\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3428 - accuracy: 0.8100 - val_loss: 0.4558 - val_accuracy: 0.8060\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3421 - accuracy: 0.8100 - val_loss: 0.4541 - val_accuracy: 0.8100\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3421 - accuracy: 0.8200 - val_loss: 0.4527 - val_accuracy: 0.8150\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3431 - accuracy: 0.8200 - val_loss: 0.4529 - val_accuracy: 0.8170\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3456 - accuracy: 0.8300 - val_loss: 0.4533 - val_accuracy: 0.8170\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3460 - accuracy: 0.8300 - val_loss: 0.4532 - val_accuracy: 0.8170\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3445 - accuracy: 0.8300 - val_loss: 0.4530 - val_accuracy: 0.8150\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3430 - accuracy: 0.8200 - val_loss: 0.4537 - val_accuracy: 0.8130\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3414 - accuracy: 0.8200 - val_loss: 0.4550 - val_accuracy: 0.8100\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3407 - accuracy: 0.8100 - val_loss: 0.4561 - val_accuracy: 0.8120\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3416 - accuracy: 0.8200 - val_loss: 0.4574 - val_accuracy: 0.8110\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3415 - accuracy: 0.8300 - val_loss: 0.4582 - val_accuracy: 0.8100\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3415 - accuracy: 0.8300 - val_loss: 0.4581 - val_accuracy: 0.8110\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3411 - accuracy: 0.8400 - val_loss: 0.4578 - val_accuracy: 0.8120\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3413 - accuracy: 0.8400 - val_loss: 0.4584 - val_accuracy: 0.8150\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3408 - accuracy: 0.8300 - val_loss: 0.4582 - val_accuracy: 0.8140\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3404 - accuracy: 0.8300 - val_loss: 0.4582 - val_accuracy: 0.8150\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3400 - accuracy: 0.8300 - val_loss: 0.4581 - val_accuracy: 0.8130\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3402 - accuracy: 0.8000 - val_loss: 0.4579 - val_accuracy: 0.8150\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3402 - accuracy: 0.8000 - val_loss: 0.4572 - val_accuracy: 0.8150\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3392 - accuracy: 0.8200 - val_loss: 0.4564 - val_accuracy: 0.8120\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3388 - accuracy: 0.8200 - val_loss: 0.4552 - val_accuracy: 0.8130\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3396 - accuracy: 0.8200 - val_loss: 0.4540 - val_accuracy: 0.8160\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3394 - accuracy: 0.8200 - val_loss: 0.4540 - val_accuracy: 0.8160\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3396 - accuracy: 0.8200 - val_loss: 0.4543 - val_accuracy: 0.8130\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3391 - accuracy: 0.8300 - val_loss: 0.4556 - val_accuracy: 0.8090\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3386 - accuracy: 0.8300 - val_loss: 0.4567 - val_accuracy: 0.8060\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3383 - accuracy: 0.8200 - val_loss: 0.4549 - val_accuracy: 0.8080\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3387 - accuracy: 0.8500 - val_loss: 0.4540 - val_accuracy: 0.8110\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3417 - accuracy: 0.8400 - val_loss: 0.4539 - val_accuracy: 0.8170\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3426 - accuracy: 0.8400 - val_loss: 0.4535 - val_accuracy: 0.8190\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3426 - accuracy: 0.8400 - val_loss: 0.4532 - val_accuracy: 0.8200\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3417 - accuracy: 0.8400 - val_loss: 0.4527 - val_accuracy: 0.8200\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3404 - accuracy: 0.8400 - val_loss: 0.4526 - val_accuracy: 0.8180\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3400 - accuracy: 0.8500 - val_loss: 0.4529 - val_accuracy: 0.8160\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3384 - accuracy: 0.8500 - val_loss: 0.4526 - val_accuracy: 0.8160\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3397 - accuracy: 0.8500 - val_loss: 0.4528 - val_accuracy: 0.8160\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3396 - accuracy: 0.8500 - val_loss: 0.4529 - val_accuracy: 0.8160\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3381 - accuracy: 0.8400 - val_loss: 0.4527 - val_accuracy: 0.8140\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3381 - accuracy: 0.8400 - val_loss: 0.4534 - val_accuracy: 0.8150\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3370 - accuracy: 0.8400 - val_loss: 0.4541 - val_accuracy: 0.8160\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3370 - accuracy: 0.8200 - val_loss: 0.4544 - val_accuracy: 0.8180\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3374 - accuracy: 0.8300 - val_loss: 0.4568 - val_accuracy: 0.8180\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3381 - accuracy: 0.8500 - val_loss: 0.4585 - val_accuracy: 0.8180\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3390 - accuracy: 0.8600 - val_loss: 0.4580 - val_accuracy: 0.8200\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3381 - accuracy: 0.8600 - val_loss: 0.4572 - val_accuracy: 0.8190\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3369 - accuracy: 0.8600 - val_loss: 0.4570 - val_accuracy: 0.8190\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3365 - accuracy: 0.8400 - val_loss: 0.4566 - val_accuracy: 0.8190\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3362 - accuracy: 0.8400 - val_loss: 0.4569 - val_accuracy: 0.8210\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3362 - accuracy: 0.8400 - val_loss: 0.4573 - val_accuracy: 0.8210\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3359 - accuracy: 0.8300 - val_loss: 0.4585 - val_accuracy: 0.8210\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3361 - accuracy: 0.8500 - val_loss: 0.4586 - val_accuracy: 0.8190\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3365 - accuracy: 0.8500 - val_loss: 0.4569 - val_accuracy: 0.8230\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3358 - accuracy: 0.8300 - val_loss: 0.4557 - val_accuracy: 0.8250\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3354 - accuracy: 0.8300 - val_loss: 0.4547 - val_accuracy: 0.8250\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3351 - accuracy: 0.8400 - val_loss: 0.4539 - val_accuracy: 0.8220\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3343 - accuracy: 0.8400 - val_loss: 0.4540 - val_accuracy: 0.8240\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8400 - val_loss: 0.4544 - val_accuracy: 0.8220\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3335 - accuracy: 0.8400 - val_loss: 0.4548 - val_accuracy: 0.8180\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3336 - accuracy: 0.8400 - val_loss: 0.4561 - val_accuracy: 0.8130\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8400 - val_loss: 0.4573 - val_accuracy: 0.8160\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3341 - accuracy: 0.8400 - val_loss: 0.4584 - val_accuracy: 0.8110\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3337 - accuracy: 0.8400 - val_loss: 0.4595 - val_accuracy: 0.8060\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3338 - accuracy: 0.8400 - val_loss: 0.4613 - val_accuracy: 0.8040\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8500 - val_loss: 0.4607 - val_accuracy: 0.8050\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3339 - accuracy: 0.8500 - val_loss: 0.4595 - val_accuracy: 0.8100\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8300 - val_loss: 0.4582 - val_accuracy: 0.8130\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.8300 - val_loss: 0.4581 - val_accuracy: 0.8100\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8400 - val_loss: 0.4581 - val_accuracy: 0.8090\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8500 - val_loss: 0.4578 - val_accuracy: 0.8120\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8500 - val_loss: 0.4573 - val_accuracy: 0.8160\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3336 - accuracy: 0.8500 - val_loss: 0.4571 - val_accuracy: 0.8200\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3352 - accuracy: 0.8400 - val_loss: 0.4572 - val_accuracy: 0.8190\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3391 - accuracy: 0.8400 - val_loss: 0.4578 - val_accuracy: 0.8220\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3397 - accuracy: 0.8400 - val_loss: 0.4551 - val_accuracy: 0.8280\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3354 - accuracy: 0.8500 - val_loss: 0.4531 - val_accuracy: 0.8250\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3324 - accuracy: 0.8400 - val_loss: 0.4544 - val_accuracy: 0.8260\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3321 - accuracy: 0.8400 - val_loss: 0.4572 - val_accuracy: 0.8170\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8400 - val_loss: 0.4588 - val_accuracy: 0.8140\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8300 - val_loss: 0.4595 - val_accuracy: 0.8130\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8400 - val_loss: 0.4589 - val_accuracy: 0.8150\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8400 - val_loss: 0.4568 - val_accuracy: 0.8220\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3312 - accuracy: 0.8400 - val_loss: 0.4539 - val_accuracy: 0.8220\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8300 - val_loss: 0.4531 - val_accuracy: 0.8220\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3311 - accuracy: 0.8400 - val_loss: 0.4535 - val_accuracy: 0.8190\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3313 - accuracy: 0.8200 - val_loss: 0.4538 - val_accuracy: 0.8180\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3309 - accuracy: 0.8300 - val_loss: 0.4544 - val_accuracy: 0.8160\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3304 - accuracy: 0.8300 - val_loss: 0.4553 - val_accuracy: 0.8140\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3304 - accuracy: 0.8400 - val_loss: 0.4560 - val_accuracy: 0.8130\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3302 - accuracy: 0.8400 - val_loss: 0.4561 - val_accuracy: 0.8130\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3300 - accuracy: 0.8400 - val_loss: 0.4566 - val_accuracy: 0.8130\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3296 - accuracy: 0.8400 - val_loss: 0.4573 - val_accuracy: 0.8120\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3291 - accuracy: 0.8500 - val_loss: 0.4582 - val_accuracy: 0.8110\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3294 - accuracy: 0.8500 - val_loss: 0.4587 - val_accuracy: 0.8090\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8500 - val_loss: 0.4592 - val_accuracy: 0.8090\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3294 - accuracy: 0.8500 - val_loss: 0.4602 - val_accuracy: 0.8040\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3293 - accuracy: 0.8500 - val_loss: 0.4604 - val_accuracy: 0.8060\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainy, validation_data=(testX, testy),\n",
    "                    epochs=500,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23abe209",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f714fd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.850, Test: 0.806\n"
     ]
    }
   ],
   "source": [
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b39f3c",
   "metadata": {},
   "source": [
    "#### Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf11bfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "935fd29b",
   "metadata": {},
   "source": [
    "ALL STEPS COMBINED()\n",
    "# develop an mlp for blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "print(trainX.shape, testX.shape)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=500, verbose=0)\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# learning curves of model accuracy\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74889709",
   "metadata": {},
   "source": [
    "## Chapter 04. Train and Save Sub-Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b866f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A FUNCTION to DEFINE & FIT an MLP MODEL\n",
    "\n",
    "def fit_model(trainX, trainy):\n",
    "    # Model deifinition\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Fitting the model\n",
    "    model.fit(trainX, trainy, epochs=500, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a36a0",
   "metadata": {},
   "source": [
    "#### Creating Multiple MLP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7747ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved ensemble_models/mlp/model_1.h5\n",
      ">Saved ensemble_models/mlp/model_2.h5\n",
      ">Saved ensemble_models/mlp/model_3.h5\n",
      ">Saved ensemble_models/mlp/model_4.h5\n",
      ">Saved ensemble_models/mlp/model_5.h5\n"
     ]
    }
   ],
   "source": [
    "n_members = 5\n",
    "\n",
    "for i in range(n_members):\n",
    "    # Fitting the model\n",
    "    model = fit_model(trainX, trainy)\n",
    "    \n",
    "    # Saving the model\n",
    "    filename = 'ensemble_models/mlp/model_' + str(i + 1) + '.h5'\n",
    "    model.save(filename)\n",
    "    print('>Saved %s' % filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28b2d9",
   "metadata": {},
   "source": [
    "## Chapter 05. Separate Stacking Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0810b",
   "metadata": {},
   "source": [
    "In this section, a meta-learner that will best combine the predictions from the sub-models and ideally perform better than any single sub-model will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "620d7325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d31795ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models from file\n",
    "def load_all_models(n_models):\n",
    "    all_models = list()\n",
    "    for i in range(n_models):\n",
    "        # define filename for this ensemble\n",
    "        filename = 'ensemble_models/mlp/model_' + str(i + 1) + '.h5'\n",
    "        # load model from file\n",
    "        model = load_model(filename)\n",
    "        # add to list of members\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df351912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded ensemble_models/mlp/model_1.h5\n",
      ">loaded ensemble_models/mlp/model_2.h5\n",
      ">loaded ensemble_models/mlp/model_3.h5\n",
      ">loaded ensemble_models/mlp/model_4.h5\n",
      ">loaded ensemble_models/mlp/model_5.h5\n",
      "Loaded 5 models\n"
     ]
    }
   ],
   "source": [
    "# load all models\n",
    "n_members = 5\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5822552",
   "metadata": {},
   "source": [
    "It would be useful to know how well the single models perform on the test dataset as we would expect a stacking model to perform better.\n",
    "\n",
    "We can easily evaluate each single model on the training dataset and establish a baseline of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5d8d1402",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1176 test_step\n        self.compiled_loss(\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 3, 2) and (None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-e9b667d5ff25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtesty_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesty_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model Accuracy: %.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TraceContext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1176 test_step\n        self.compiled_loss(\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\uuresin\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 3, 2) and (None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# evaluate standalone models on test dataset\n",
    "for model in members:\n",
    "    testy_enc = to_categorical(testy)\n",
    "    _, acc = model.evaluate(testX, testy_enc, verbose=0)\n",
    "    print('Model Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e09395df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6d3f80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db843b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0092321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
